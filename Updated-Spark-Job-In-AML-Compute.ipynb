{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure SDK version: 1.0.76\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "\n",
    "print(\"Azure SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cesardl-automl-northcentralus-ws\n",
      "automlpmdemo\n",
      "northcentralus\n",
      "102a16c3-37d3-48a8-9237-4c9b1e8e80e0\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "envs = Environment.list(workspace=ws)\n",
    "        \n",
    "# Use curated environment for Spark\n",
    "spark_curated_environment = Environment.get(workspace=ws, name=\"AzureML-PySpark-MmlSpark-0.15\")\n",
    "\n",
    "# Copy based on curated environment\n",
    "spark_env = spark_curated_environment\n",
    "spark_env.name = \"Custom-AzureML-PySpark-Environment\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Environment with newer Docker Spark Image\n",
    "from azureml.core import ContainerRegistry\n",
    "\n",
    "# Set base Docker Image\n",
    "spark_env.docker.enabled = True\n",
    "\n",
    "# Specify custom Docker base image and registry, if you don't want to use the defaults\n",
    "spark_env.docker.base_image=\"mcr.microsoft.com/mmlspark/release\" \n",
    "container_registry = ContainerRegistry()\n",
    "container_registry.address = \"mcr.microsoft.com\"\n",
    "# container_registry.username = \"\"   # Use username if using a private Docker Registry like ACR\n",
    "# container_registry.password = \"\"   # Use password if using a private Docker Registry like ACR\n",
    "spark_env.docker.base_image_registry=container_registry\n",
    "\n",
    "spark_env.save_to_directory(path=\"./spark_environment_definition\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'spark-experiment-on-aml-compute'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute = ws.compute_targets[\"cpu-cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./project-submit-folder/iris.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create project directory and copy the training script into the project directory\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "project_folder = './project-submit-folder'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "\n",
    "# Copy the needed files\n",
    "shutil.copy('spark-job.py', project_folder)\n",
    "shutil.copy('spark-job-simple.py', project_folder)\n",
    "shutil.copy('iris.csv', project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig, RunConfiguration, Experiment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "## use pyspark framework\n",
    "spark_run_config = RunConfiguration(framework=\"pyspark\")\n",
    "spark_run_config.environment = spark_env\n",
    "spark_run_config.target = compute\n",
    "\n",
    "scriptconfig = ScriptRunConfig(source_directory=\"project-submit-folder\", \n",
    "                               script=\"spark-job.py\",\n",
    "                               run_config = spark_run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>spark-experiment-on-aml-compute</td><td>spark-experiment-on-aml-compute_1580154909_5540b098</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://ml.azure.com/experiments/spark-experiment-on-aml-compute/runs/spark-experiment-on-aml-compute_1580154909_5540b098?wsid=/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourcegroups/automlpmdemo/workspaces/cesardl-automl-northcentralus-ws\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: spark-experiment-on-aml-compute,\n",
       "Id: spark-experiment-on-aml-compute_1580154909_5540b098,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = experiment.submit(scriptconfig)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba00a73cb6b421fb871851c856a091e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'NOTSET',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Failed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/spark-experiment-on-aml-compute/runs/spark-experiment-on-aml-compute_1580154909_5540b098?wsid=/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourcegroups/automlpmdemo/workspaces/cesardl-automl-northcentralus-ws\", \"run_id\": \"spark-experiment-on-aml-compute_1580154909_5540b098\", \"run_properties\": {\"run_id\": \"spark-experiment-on-aml-compute_1580154909_5540b098\", \"created_utc\": \"2020-01-27T19:55:12.176124Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"d586266a-0ae2-4ce0-b56c-4f44705715c2\", \"azureml.git.repository_uri\": \"https://github.com/CESARDELATORRE/poc-spark-aml.git\", \"mlflow.source.git.repoURL\": \"https://github.com/CESARDELATORRE/poc-spark-aml.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"1439a4e5aab5532f08809258f56c6a12f04e3c32\", \"mlflow.source.git.commit\": \"1439a4e5aab5532f08809258f56c6a12f04e3c32\", \"azureml.git.dirty\": \"True\", \"AzureML.DerivedImageName\": \"azureml/azureml_5791559675f375a8eab3c368318bea04\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-01-27T19:56:24.890477Z\", \"status\": \"Failed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580154909_5540b098/azureml-logs/55_azureml-execution-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt?sv=2019-02-02&sr=b&sig=bvwWWo%2FXzs%2BwhNjggoQ6lo5E%2FUsFG6ushp7emclhWxw%3D&st=2020-01-27T19%3A46%3A25Z&se=2020-01-28T03%3A56%3A25Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580154909_5540b098/azureml-logs/65_job_prep-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt?sv=2019-02-02&sr=b&sig=AvC1lRKOw2q2puOXNwhQsSRxpDvrAUO8mrEVam6%2FulU%3D&st=2020-01-27T19%3A46%3A25Z&se=2020-01-28T03%3A56%3A25Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580154909_5540b098/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=Vw2g5jcmqXqtL42YAJWTgYgkPrFvrZ7GssZH9sIIeYs%3D&st=2020-01-27T19%3A46%3A25Z&se=2020-01-28T03%3A56%3A25Z&sp=r\", \"azureml-logs/75_job_post-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580154909_5540b098/azureml-logs/75_job_post-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt?sv=2019-02-02&sr=b&sig=bY70%2F9O%2F9T9WbbY8LdqqGH1PWfWR1PWzX0xlTc2UJBI%3D&st=2020-01-27T19%3A46%3A25Z&se=2020-01-28T03%3A56%3A25Z&sp=r\", \"azureml-logs/process_info.json\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580154909_5540b098/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=B%2FRcAU%2B53WooZmulP3zqXywOKhxp4AskMaJH0I602FQ%3D&st=2020-01-27T19%3A46%3A25Z&se=2020-01-28T03%3A56%3A25Z&sp=r\", \"azureml-logs/process_status.json\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580154909_5540b098/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=ByoxPhdA1RBmFaGLwlwzCDwPzL3%2Fj7obF40dEReE8aM%3D&st=2020-01-27T19%3A46%3A25Z&se=2020-01-28T03%3A56%3A25Z&sp=r\", \"logs/azureml/azureml.log\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580154909_5540b098/logs/azureml/azureml.log?sv=2019-02-02&sr=b&sig=YTjUk9%2BvJcsuL1UvPyyZoMx59I3zIj8ZwHs4WA%2F3tYM%3D&st=2020-01-27T19%3A46%3A25Z&se=2020-01-28T03%3A56%3A25Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt\"]], \"run_duration\": \"0:01:12\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"bash: /azureml-envs/azureml_2d6f32a8b5b445b7627fd1ae36599989/lib/libtinfo.so.5: no version information available (required by bash)\\r\\nStarting job release. Current time:2020-01-27T19:56:10.550849\\r\\nLogging experiment finalizing status in history service.\\r\\nStarting the daemon thread to refresh tokens in background for process with pid = 413\\r\\nJob release is complete. Current time:2020-01-27T19:56:12.630861\\r\\n\\nError occurred: AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"NOTSET\", \"sdk_version\": \"1.0.76\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Monitor run\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# See files associated with the 'Best run'\n",
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Regularization Rate': 0.01, 'Accuracy': 0.9787234042553191}\n"
     ]
    }
   ],
   "source": [
    "# get all metris logged in the run\n",
    "metrics = run.get_metrics()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
