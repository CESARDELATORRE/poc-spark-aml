{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure SDK version: 1.0.76\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "\n",
    "print(\"Azure SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cesardl-automl-northcentralus-ws\n",
      "automlpmdemo\n",
      "northcentralus\n",
      "102a16c3-37d3-48a8-9237-4c9b1e8e80e0\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "envs = Environment.list(workspace=ws)\n",
    "        \n",
    "# Use curated environment for Spark\n",
    "spark_env = Environment.get(workspace=ws, name=\"AzureML-PySpark-MmlSpark-0.15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'spark-experiment-on-aml-compute'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute = ws.compute_targets[\"cpu-cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./project-submit-folder/iris.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create project directory and copy the training script into the project directory\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "project_folder = './project-submit-folder'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "\n",
    "# Copy the needed files\n",
    "shutil.copy('spark-job.py', project_folder)\n",
    "shutil.copy('spark-job-simple.py', project_folder)\n",
    "shutil.copy('iris.csv', project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig, RunConfiguration, Experiment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "## use pyspark framework\n",
    "spark_run_config = RunConfiguration(framework=\"pyspark\")\n",
    "spark_run_config.environment = spark_env\n",
    "spark_run_config.target = compute\n",
    "\n",
    "scriptconfig = ScriptRunConfig(source_directory=\"project-submit-folder\", \n",
    "                               script=\"spark-job.py\",\n",
    "                               run_config = spark_run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>spark-experiment-on-aml-compute</td><td>spark-experiment-on-aml-compute_1580155063_b95d3594</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://ml.azure.com/experiments/spark-experiment-on-aml-compute/runs/spark-experiment-on-aml-compute_1580155063_b95d3594?wsid=/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourcegroups/automlpmdemo/workspaces/cesardl-automl-northcentralus-ws\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: spark-experiment-on-aml-compute,\n",
       "Id: spark-experiment-on-aml-compute_1580155063_b95d3594,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = experiment.submit(scriptconfig)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d387c53cd24d03b881b93e2c35e854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'NOTSET',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/spark-experiment-on-aml-compute/runs/spark-experiment-on-aml-compute_1580155063_b95d3594?wsid=/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourcegroups/automlpmdemo/workspaces/cesardl-automl-northcentralus-ws\", \"run_id\": \"spark-experiment-on-aml-compute_1580155063_b95d3594\", \"run_properties\": {\"run_id\": \"spark-experiment-on-aml-compute_1580155063_b95d3594\", \"created_utc\": \"2020-01-27T19:57:45.68316Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"d586266a-0ae2-4ce0-b56c-4f44705715c2\", \"azureml.git.repository_uri\": \"https://github.com/CESARDELATORRE/poc-spark-aml.git\", \"mlflow.source.git.repoURL\": \"https://github.com/CESARDELATORRE/poc-spark-aml.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"1439a4e5aab5532f08809258f56c6a12f04e3c32\", \"mlflow.source.git.commit\": \"1439a4e5aab5532f08809258f56c6a12f04e3c32\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-01-27T19:59:03.792456Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580155063_b95d3594/azureml-logs/55_azureml-execution-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt?sv=2019-02-02&sr=b&sig=5BICkT1lB8X%2BxR1WmJ4fRPah6F8nfn7G9j75L9mV7dA%3D&st=2020-01-27T19%3A49%3A10Z&se=2020-01-28T03%3A59%3A10Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580155063_b95d3594/azureml-logs/65_job_prep-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt?sv=2019-02-02&sr=b&sig=kDECdKHOfRcmVx3W%2BtP521k4Tbbw360VFIct9lhgYYk%3D&st=2020-01-27T19%3A49%3A10Z&se=2020-01-28T03%3A59%3A10Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580155063_b95d3594/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=eJBuxd4e3%2BGhPaRlWpB%2FtqodMy%2BcgSRDD%2FQJgjgb%2BGI%3D&st=2020-01-27T19%3A49%3A10Z&se=2020-01-28T03%3A59%3A10Z&sp=r\", \"azureml-logs/75_job_post-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580155063_b95d3594/azureml-logs/75_job_post-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt?sv=2019-02-02&sr=b&sig=potRBRnQQBUyUlMAChCPtRYGB3Qqu0AeZQdinyMMFw8%3D&st=2020-01-27T19%3A49%3A10Z&se=2020-01-28T03%3A59%3A10Z&sp=r\", \"azureml-logs/process_info.json\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580155063_b95d3594/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=SJAWkrNcpOsEydlk5q9BsbCN%2FCLTM%2F5A4X002QSHLN0%3D&st=2020-01-27T19%3A49%3A10Z&se=2020-01-28T03%3A59%3A10Z&sp=r\", \"azureml-logs/process_status.json\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580155063_b95d3594/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=n1Smpn8zsSRRWaAic91KqDtO5mkrJ0%2FXZ%2FMllvRDoeg%3D&st=2020-01-27T19%3A49%3A10Z&se=2020-01-28T03%3A59%3A10Z&sp=r\", \"logs/azureml/580_azureml.log\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580155063_b95d3594/logs/azureml/580_azureml.log?sv=2019-02-02&sr=b&sig=noSWBO3hIMrikImigeo%2FmLWqp7YaTgMJQd75tLKLReI%3D&st=2020-01-27T19%3A49%3A10Z&se=2020-01-28T03%3A59%3A10Z&sp=r\", \"logs/azureml/azureml.log\": \"https://cesardlautomln5648400225.blob.core.windows.net/azureml/ExperimentRun/dcid.spark-experiment-on-aml-compute_1580155063_b95d3594/logs/azureml/azureml.log?sv=2019-02-02&sr=b&sig=O19nqNWNA0PH2rOyAVTLmCyonyOT88KPWWilZrWCq2Q%3D&st=2020-01-27T19%3A49%3A10Z&se=2020-01-28T03%3A59%3A10Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_b10e0585cbc55e9ebac71bd84109e0836d1d2d6cd0de8c43a4a06f9c94ee8f10_d.txt\"], [\"logs/azureml/580_azureml.log\"]], \"run_duration\": \"0:01:18\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"spark-experiment-on-aml-compute_1580155063_b95d3594\", \"categories\": [0], \"series\": [{\"data\": [0.01]}]}, {\"name\": \"Accuracy\", \"run_id\": \"spark-experiment-on-aml-compute_1580155063_b95d3594\", \"categories\": [0], \"series\": [{\"data\": [0.9583333333333334]}]}], \"run_logs\": \"2020-01-27 19:58:20,080|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2020-01-27 19:58:20,081|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2020-01-27 19:58:20,413|azureml.history._tracking.PythonWorkingDirectory|DEBUG|PySpark found in environment.\\n2020-01-27 19:58:20,413|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2020-01-27 19:58:20,693|azureml._base_sdk_common.user_agent|DEBUG|Fetching client info from /home/mmlspark/.azureml/clientinfo.json\\n2020-01-27 19:58:20,694|azureml._base_sdk_common.user_agent|DEBUG|Error loading client info: [Errno 2] No such file or directory: '/home/mmlspark/.azureml/clientinfo.json'\\n2020-01-27 19:58:21,058|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2020-01-27 19:58:21,058|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2020-01-27 19:58:21,058|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2020-01-27 19:58:21,058|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2020-01-27 19:58:21,058|azureml.core.run|DEBUG|Adding new factory <function HyperDriveRun._from_run_dto at 0x7f4087f0fc80> for run source hyperdrive\\n2020-01-27 19:58:21,066|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f40a48f0620> for run source azureml.scriptrun\\n2020-01-27 19:58:21,068|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-01-27 19:58:21,076|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-01-27 19:58:21,077|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2020-01-27 19:58:21,077|azureml.core.authentication|DEBUG|Time to expire 1814363.922379 seconds\\n2020-01-27 19:58:21,078|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,078|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,078|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,078|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,079|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,079|azureml._base_sdk_common.service_discovery|DEBUG|Constructing mms service url in from history url environment variable None, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,079|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,079|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,079|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,115|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,122|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-01-27 19:58:21,132|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-01-27 19:58:21,139|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-01-27 19:58:21,147|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-01-27 19:58:21,154|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-01-27 19:58:21,154|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2020-01-27 19:58:21,155|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-01-27 19:58:21,155|msrest.http_logger|DEBUG|Request URL: 'https://northcentralus.experiments.azureml.net/history/v1.0/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourceGroups/automlpmdemo/providers/Microsoft.MachineLearningServices/workspaces/cesardl-automl-northcentralus-ws/experiments/spark-experiment-on-aml-compute/runs/spark-experiment-on-aml-compute_1580155063_b95d3594'\\n2020-01-27 19:58:21,156|msrest.http_logger|DEBUG|Request method: 'GET'\\n2020-01-27 19:58:21,156|msrest.http_logger|DEBUG|Request headers:\\n2020-01-27 19:58:21,156|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-01-27 19:58:21,156|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2020-01-27 19:58:21,156|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '2c766690-8fe5-46df-a5b2-47503e72190b'\\n2020-01-27 19:58:21,156|msrest.http_logger|DEBUG|    'request-id': '2c766690-8fe5-46df-a5b2-47503e72190b'\\n2020-01-27 19:58:21,156|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.2 (Linux-4.15.0-1057-azure-x86_64-with-debian-stretch-sid) msrest/0.6.10 azureml._restclient/core.1.0.81'\\n2020-01-27 19:58:21,156|msrest.http_logger|DEBUG|Request body:\\n2020-01-27 19:58:21,156|msrest.http_logger|DEBUG|None\\n2020-01-27 19:58:21,157|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-01-27 19:58:21,157|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-01-27 19:58:21,157|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-01-27 19:58:21,157|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-01-27 19:58:21,319|msrest.http_logger|DEBUG|Response status: 200\\n2020-01-27 19:58:21,319|msrest.http_logger|DEBUG|Response headers:\\n2020-01-27 19:58:21,319|msrest.http_logger|DEBUG|    'Date': 'Mon, 27 Jan 2020 19:58:21 GMT'\\n2020-01-27 19:58:21,319|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2020-01-27 19:58:21,320|msrest.http_logger|DEBUG|    'Transfer-Encoding': 'chunked'\\n2020-01-27 19:58:21,320|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-01-27 19:58:21,320|msrest.http_logger|DEBUG|    'Vary': 'Accept-Encoding'\\n2020-01-27 19:58:21,320|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-01-27 19:58:21,320|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '2c766690-8fe5-46df-a5b2-47503e72190b'\\n2020-01-27 19:58:21,320|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-01-27 19:58:21,320|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-01-27 19:58:21,320|msrest.http_logger|DEBUG|    'X-Content-Type-Options': 'nosniff'\\n2020-01-27 19:58:21,320|msrest.http_logger|DEBUG|    'Content-Encoding': 'gzip'\\n2020-01-27 19:58:21,321|msrest.http_logger|DEBUG|Response content:\\n2020-01-27 19:58:21,321|msrest.http_logger|DEBUG|{\\n  \\\"runNumber\\\": 9,\\n  \\\"rootRunId\\\": \\\"spark-experiment-on-aml-compute_1580155063_b95d3594\\\",\\n  \\\"experimentId\\\": \\\"3e417a53-a5b6-455d-b737-9e201c335140\\\",\\n  \\\"createdUtc\\\": \\\"2020-01-27T19:57:45.6831607+00:00\\\",\\n  \\\"createdBy\\\": {\\n    \\\"userObjectId\\\": \\\"6f9fb7d1-417b-46ae-9591-e9a89dfe7142\\\",\\n    \\\"userPuId\\\": \\\"10033FFF801BF74F\\\",\\n    \\\"userIdp\\\": null,\\n    \\\"userAltSecId\\\": null,\\n    \\\"userIss\\\": \\\"https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/\\\",\\n    \\\"userTenantId\\\": \\\"72f988bf-86f1-41af-91ab-2d7cd011db47\\\",\\n    \\\"userName\\\": \\\"Cesar De la Torre Llorente\\\"\\n  },\\n  \\\"userId\\\": \\\"6f9fb7d1-417b-46ae-9591-e9a89dfe7142\\\",\\n  \\\"token\\\": null,\\n  \\\"tokenExpiryTimeUtc\\\": null,\\n  \\\"error\\\": null,\\n  \\\"warnings\\\": [\\n    {\\n      \\\"source\\\": null,\\n      \\\"message\\\": \\\"This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\\\\nPlease enable Docker in the environment section of your run configuration to stop seeing this warning message.\\\"\\n    }\\n  ],\\n  \\\"revision\\\": 7,\\n  \\\"runUuid\\\": \\\"85e1adad-72b3-4d21-90e9-e9958866c07a\\\",\\n  \\\"parentRunUuid\\\": null,\\n  \\\"rootRunUuid\\\": \\\"85e1adad-72b3-4d21-90e9-e9958866c07a\\\",\\n  \\\"runId\\\": \\\"spark-experiment-on-aml-compute_1580155063_b95d3594\\\",\\n  \\\"parentRunId\\\": null,\\n  \\\"status\\\": \\\"Running\\\",\\n  \\\"startTimeUtc\\\": \\\"2020-01-27T19:57:59.7375754+00:00\\\",\\n  \\\"endTimeUtc\\\": null,\\n  \\\"heartbeatEnabled\\\": false,\\n  \\\"options\\\": {\\n    \\\"generateDataContainerIdIfNotSpecified\\\": true\\n  },\\n  \\\"name\\\": null,\\n  \\\"dataContainerId\\\": \\\"dcid.spark-experiment-on-aml-compute_1580155063_b95d3594\\\",\\n  \\\"description\\\": null,\\n  \\\"hidden\\\": false,\\n  \\\"runType\\\": \\\"azureml.scriptrun\\\",\\n  \\\"properties\\\": {\\n    \\\"_azureml.ComputeTargetType\\\": \\\"amlcompute\\\",\\n    \\\"ContentSnapshotId\\\": \\\"d586266a-0ae2-4ce0-b56c-4f44705715c2\\\",\\n    \\\"azureml.git.repository_uri\\\": \\\"https://github.com/CESARDELATORRE/poc-spark-aml.git\\\",\\n    \\\"mlflow.source.git.repoURL\\\": \\\"https://github.com/CESARDELATORRE/poc-spark-aml.git\\\",\\n    \\\"azureml.git.branch\\\": \\\"master\\\",\\n    \\\"mlflow.source.git.branch\\\": \\\"master\\\",\\n    \\\"azureml.git.commit\\\": \\\"1439a4e5aab5532f08809258f56c6a12f04e3c32\\\",\\n    \\\"mlflow.source.git.commit\\\": \\\"1439a4e5aab5532f08809258f56c6a12f04e3c32\\\",\\n    \\\"azureml.git.dirty\\\": \\\"True\\\",\\n    \\\"ProcessInfoFile\\\": \\\"azureml-logs/process_info.json\\\",\\n    \\\"ProcessStatusFile\\\": \\\"azureml-logs/process_status.json\\\"\\n  },\\n  \\\"scriptName\\\": \\\"spark-job.py\\\",\\n  \\\"target\\\": \\\"cpu-cluster\\\",\\n  \\\"tags\\\": {},\\n  \\\"inputDatasets\\\": [],\\n  \\\"runDefinition\\\": null,\\n  \\\"createdFrom\\\": null,\\n  \\\"cancelUri\\\": \\\"https://northcentralus.experiments.azureml.net/execution/v1.0/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourceGroups/automlpmdemo/providers/Microsoft.MachineLearningServices/workspaces/cesardl-automl-northcentralus-ws/experiments/spark-experiment-on-aml-compute/runId/spark-experiment-on-aml-compute_1580155063_b95d3594/cancel\\\",\\n  \\\"completeUri\\\": null,\\n  \\\"diagnosticsUri\\\": \\\"https://northcentralus.experiments.azureml.net/execution/v1.0/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourceGroups/automlpmdemo/providers/Microsoft.MachineLearningServices/workspaces/cesardl-automl-northcentralus-ws/experiments/spark-experiment-on-aml-compute/runId/spark-experiment-on-aml-compute_1580155063_b95d3594/diagnostics\\\",\\n  \\\"computeRequest\\\": {\\n    \\\"nodeCount\\\": 1\\n  },\\n  \\\"retainForLifetimeOfWorkspace\\\": false,\\n  \\\"queueingInfo\\\": null\\n}\\n2020-01-27 19:58:21,329|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2020-01-27 19:58:21,330|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'd586266a-0ae2-4ce0-b56c-4f44705715c2', 'azureml.git.repository_uri': 'https://github.com/CESARDELATORRE/poc-spark-aml.git', 'mlflow.source.git.repoURL': 'https://github.com/CESARDELATORRE/poc-spark-aml.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '1439a4e5aab5532f08809258f56c6a12f04e3c32', 'mlflow.source.git.commit': '1439a4e5aab5532f08809258f56c6a12f04e3c32', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-01-27 19:58:21,330|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-01-27 19:58:21,331|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2020-01-27 19:58:21,331|azureml.WorkerPool|DEBUG|[START]\\n2020-01-27 19:58:21,331|azureml.SendRunKillSignal|DEBUG|[START]\\n2020-01-27 19:58:21,331|azureml.RunStatusContext|DEBUG|[START]\\n2020-01-27 19:58:21,331|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunContextManager.RunStatusContext|DEBUG|[START]\\n2020-01-27 19:58:21,332|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2020-01-27 19:58:21,332|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2020-01-27 19:58:21,332|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-northcentralus-ws/azureml/spark-experiment-on-aml-compute_1580155063_b95d3594/mounts/workspaceblobstore/azureml/spark-experiment-on-aml-compute_1580155063_b95d3594\\n2020-01-27 19:58:21,332|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-01-27 19:58:21,332|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-northcentralus-ws/azureml/spark-experiment-on-aml-compute_1580155063_b95d3594/mounts/workspaceblobstore/azureml/spark-experiment-on-aml-compute_1580155063_b95d3594\\n2020-01-27 19:58:21,735|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,735|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,736|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,736|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,736|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,736|azureml._base_sdk_common.service_discovery|DEBUG|Constructing mms service url in from history url environment variable None, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,736|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,736|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,737|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://northcentralus.experiments.azureml.net.\\n2020-01-27 19:58:21,744|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-01-27 19:58:21,744|azureml._run_impl.run_history_facade|DEBUG|Created a static thread pool for RunHistoryFacade class\\n2020-01-27 19:58:21,751|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-01-27 19:58:21,758|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-01-27 19:58:21,765|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-01-27 19:58:21,775|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-01-27 19:58:21,777|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2020-01-27 19:58:21,777|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-01-27 19:58:21,777|msrest.http_logger|DEBUG|Request URL: 'https://northcentralus.experiments.azureml.net/history/v1.0/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourceGroups/automlpmdemo/providers/Microsoft.MachineLearningServices/workspaces/cesardl-automl-northcentralus-ws/experiments/spark-experiment-on-aml-compute/runs/spark-experiment-on-aml-compute_1580155063_b95d3594'\\n2020-01-27 19:58:21,777|msrest.http_logger|DEBUG|Request method: 'GET'\\n2020-01-27 19:58:21,778|msrest.http_logger|DEBUG|Request headers:\\n2020-01-27 19:58:21,778|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-01-27 19:58:21,778|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2020-01-27 19:58:21,778|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'fcd71bd0-23f7-4513-8b16-0050a230261f'\\n2020-01-27 19:58:21,778|msrest.http_logger|DEBUG|    'request-id': 'fcd71bd0-23f7-4513-8b16-0050a230261f'\\n2020-01-27 19:58:21,778|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.2 (Linux-4.15.0-1057-azure-x86_64-with-debian-stretch-sid) msrest/0.6.10 azureml._restclient/core.1.0.81'\\n2020-01-27 19:58:21,778|msrest.http_logger|DEBUG|Request body:\\n2020-01-27 19:58:21,778|msrest.http_logger|DEBUG|None\\n2020-01-27 19:58:21,779|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-01-27 19:58:21,779|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-01-27 19:58:21,779|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-01-27 19:58:21,779|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-01-27 19:58:21,866|msrest.http_logger|DEBUG|Response status: 200\\n2020-01-27 19:58:21,866|msrest.http_logger|DEBUG|Response headers:\\n2020-01-27 19:58:21,867|msrest.http_logger|DEBUG|    'Date': 'Mon, 27 Jan 2020 19:58:21 GMT'\\n2020-01-27 19:58:21,867|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2020-01-27 19:58:21,867|msrest.http_logger|DEBUG|    'Transfer-Encoding': 'chunked'\\n2020-01-27 19:58:21,867|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-01-27 19:58:21,867|msrest.http_logger|DEBUG|    'Vary': 'Accept-Encoding'\\n2020-01-27 19:58:21,867|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-01-27 19:58:21,867|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'fcd71bd0-23f7-4513-8b16-0050a230261f'\\n2020-01-27 19:58:21,868|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-01-27 19:58:21,868|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-01-27 19:58:21,868|msrest.http_logger|DEBUG|    'X-Content-Type-Options': 'nosniff'\\n2020-01-27 19:58:21,868|msrest.http_logger|DEBUG|    'Content-Encoding': 'gzip'\\n2020-01-27 19:58:21,868|msrest.http_logger|DEBUG|Response content:\\n2020-01-27 19:58:21,868|msrest.http_logger|DEBUG|{\\n  \\\"runNumber\\\": 9,\\n  \\\"rootRunId\\\": \\\"spark-experiment-on-aml-compute_1580155063_b95d3594\\\",\\n  \\\"experimentId\\\": \\\"3e417a53-a5b6-455d-b737-9e201c335140\\\",\\n  \\\"createdUtc\\\": \\\"2020-01-27T19:57:45.6831607+00:00\\\",\\n  \\\"createdBy\\\": {\\n    \\\"userObjectId\\\": \\\"6f9fb7d1-417b-46ae-9591-e9a89dfe7142\\\",\\n    \\\"userPuId\\\": \\\"10033FFF801BF74F\\\",\\n    \\\"userIdp\\\": null,\\n    \\\"userAltSecId\\\": null,\\n    \\\"userIss\\\": \\\"https://sts.windows.net/72f988bf-86f1-41af-91ab-2d7cd011db47/\\\",\\n    \\\"userTenantId\\\": \\\"72f988bf-86f1-41af-91ab-2d7cd011db47\\\",\\n    \\\"userName\\\": \\\"Cesar De la Torre Llorente\\\"\\n  },\\n  \\\"userId\\\": \\\"6f9fb7d1-417b-46ae-9591-e9a89dfe7142\\\",\\n  \\\"token\\\": null,\\n  \\\"tokenExpiryTimeUtc\\\": null,\\n  \\\"error\\\": null,\\n  \\\"warnings\\\": [\\n    {\\n      \\\"source\\\": null,\\n      \\\"message\\\": \\\"This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\\\\nPlease enable Docker in the environment section of your run configuration to stop seeing this warning message.\\\"\\n    }\\n  ],\\n  \\\"revision\\\": 7,\\n  \\\"runUuid\\\": \\\"85e1adad-72b3-4d21-90e9-e9958866c07a\\\",\\n  \\\"parentRunUuid\\\": null,\\n  \\\"rootRunUuid\\\": \\\"85e1adad-72b3-4d21-90e9-e9958866c07a\\\",\\n  \\\"runId\\\": \\\"spark-experiment-on-aml-compute_1580155063_b95d3594\\\",\\n  \\\"parentRunId\\\": null,\\n  \\\"status\\\": \\\"Running\\\",\\n  \\\"startTimeUtc\\\": \\\"2020-01-27T19:57:59.7375754+00:00\\\",\\n  \\\"endTimeUtc\\\": null,\\n  \\\"heartbeatEnabled\\\": false,\\n  \\\"options\\\": {\\n    \\\"generateDataContainerIdIfNotSpecified\\\": true\\n  },\\n  \\\"name\\\": null,\\n  \\\"dataContainerId\\\": \\\"dcid.spark-experiment-on-aml-compute_1580155063_b95d3594\\\",\\n  \\\"description\\\": null,\\n  \\\"hidden\\\": false,\\n  \\\"runType\\\": \\\"azureml.scriptrun\\\",\\n  \\\"properties\\\": {\\n    \\\"_azureml.ComputeTargetType\\\": \\\"amlcompute\\\",\\n    \\\"ContentSnapshotId\\\": \\\"d586266a-0ae2-4ce0-b56c-4f44705715c2\\\",\\n    \\\"azureml.git.repository_uri\\\": \\\"https://github.com/CESARDELATORRE/poc-spark-aml.git\\\",\\n    \\\"mlflow.source.git.repoURL\\\": \\\"https://github.com/CESARDELATORRE/poc-spark-aml.git\\\",\\n    \\\"azureml.git.branch\\\": \\\"master\\\",\\n    \\\"mlflow.source.git.branch\\\": \\\"master\\\",\\n    \\\"azureml.git.commit\\\": \\\"1439a4e5aab5532f08809258f56c6a12f04e3c32\\\",\\n    \\\"mlflow.source.git.commit\\\": \\\"1439a4e5aab5532f08809258f56c6a12f04e3c32\\\",\\n    \\\"azureml.git.dirty\\\": \\\"True\\\",\\n    \\\"ProcessInfoFile\\\": \\\"azureml-logs/process_info.json\\\",\\n    \\\"ProcessStatusFile\\\": \\\"azureml-logs/process_status.json\\\"\\n  },\\n  \\\"scriptName\\\": \\\"spark-job.py\\\",\\n  \\\"target\\\": \\\"cpu-cluster\\\",\\n  \\\"tags\\\": {},\\n  \\\"inputDatasets\\\": [],\\n  \\\"runDefinition\\\": null,\\n  \\\"createdFrom\\\": null,\\n  \\\"cancelUri\\\": \\\"https://northcentralus.experiments.azureml.net/execution/v1.0/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourceGroups/automlpmdemo/providers/Microsoft.MachineLearningServices/workspaces/cesardl-automl-northcentralus-ws/experiments/spark-experiment-on-aml-compute/runId/spark-experiment-on-aml-compute_1580155063_b95d3594/cancel\\\",\\n  \\\"completeUri\\\": null,\\n  \\\"diagnosticsUri\\\": \\\"https://northcentralus.experiments.azureml.net/execution/v1.0/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourceGroups/automlpmdemo/providers/Microsoft.MachineLearningServices/workspaces/cesardl-automl-northcentralus-ws/experiments/spark-experiment-on-aml-compute/runId/spark-experiment-on-aml-compute_1580155063_b95d3594/diagnostics\\\",\\n  \\\"computeRequest\\\": {\\n    \\\"nodeCount\\\": 1\\n  },\\n  \\\"retainForLifetimeOfWorkspace\\\": false,\\n  \\\"queueingInfo\\\": null\\n}\\n2020-01-27 19:58:21,871|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2020-01-27 19:58:21,871|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'd586266a-0ae2-4ce0-b56c-4f44705715c2', 'azureml.git.repository_uri': 'https://github.com/CESARDELATORRE/poc-spark-aml.git', 'mlflow.source.git.repoURL': 'https://github.com/CESARDELATORRE/poc-spark-aml.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '1439a4e5aab5532f08809258f56c6a12f04e3c32', 'mlflow.source.git.commit': '1439a4e5aab5532f08809258f56c6a12f04e3c32', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-01-27 19:58:21,872|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-01-27 19:58:33,801|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-01-27 19:58:33,801|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-01-27 19:58:33,802|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-01-27 19:58:34,802|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-01-27 19:58:34,803|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-01-27 19:58:34,803|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 1.\\n2020-01-27 19:58:34,803|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-01-27 19:58:34,804|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-01-27 19:58:34,804|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-01-27 19:58:34,805|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-01-27 19:58:34,805|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-01-27 19:58:34,805|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.0__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-01-27 19:58:34,805|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-01-27 19:58:34,806|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-01-27 19:58:34,806|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 0__log_batch to queue of approximate size: 0\\n2020-01-27 19:58:34,807|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-01-27 19:58:34,807|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-01-27 19:58:34,808|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-01-27 19:58:34,808|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-01-27 19:58:34,808|msrest.http_logger|DEBUG|Request URL: 'https://northcentralus.experiments.azureml.net/history/v1.0/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourceGroups/automlpmdemo/providers/Microsoft.MachineLearningServices/workspaces/cesardl-automl-northcentralus-ws/experiments/spark-experiment-on-aml-compute/runs/spark-experiment-on-aml-compute_1580155063_b95d3594/batch/metrics'\\n2020-01-27 19:58:34,808|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-01-27 19:58:34,809|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-01-27 19:58:34,809|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-01-27 19:58:34,809|msrest.http_logger|DEBUG|Request headers:\\n2020-01-27 19:58:34,809|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-01-27 19:58:34,809|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-01-27 19:58:34,809|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-01-27 19:58:34,810|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-01-27 19:58:34,810|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'f381c2d9-f70a-4db7-bf49-c1956dc93a27'\\n2020-01-27 19:58:34,810|msrest.http_logger|DEBUG|    'request-id': 'f381c2d9-f70a-4db7-bf49-c1956dc93a27'\\n2020-01-27 19:58:34,810|msrest.http_logger|DEBUG|    'Content-Length': '388'\\n2020-01-27 19:58:34,810|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.2 (Linux-4.15.0-1057-azure-x86_64-with-debian-stretch-sid) msrest/0.6.10 azureml._restclient/core.1.0.81 sdk_run'\\n2020-01-27 19:58:34,811|msrest.http_logger|DEBUG|Request body:\\n2020-01-27 19:58:34,811|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"557aa461-94ee-4810-b551-ba0265fc136c\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-01-27T19:58:33.801417Z\\\", \\\"name\\\": \\\"Regularization Rate\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Regularization Rate\\\": 0.01}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Regularization Rate\\\", \\\"name\\\": \\\"Regularization Rate\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-01-27 19:58:34,811|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-01-27 19:58:34,811|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-01-27 19:58:34,811|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-01-27 19:58:34,811|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-01-27 19:58:35,116|msrest.http_logger|DEBUG|Response status: 200\\n2020-01-27 19:58:35,116|msrest.http_logger|DEBUG|Response headers:\\n2020-01-27 19:58:35,116|msrest.http_logger|DEBUG|    'Date': 'Mon, 27 Jan 2020 19:58:35 GMT'\\n2020-01-27 19:58:35,116|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-01-27 19:58:35,116|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-01-27 19:58:35,116|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-01-27 19:58:35,116|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'f381c2d9-f70a-4db7-bf49-c1956dc93a27'\\n2020-01-27 19:58:35,117|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-01-27 19:58:35,117|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-01-27 19:58:35,117|msrest.http_logger|DEBUG|    'X-Content-Type-Options': 'nosniff'\\n2020-01-27 19:58:35,117|msrest.http_logger|DEBUG|Response content:\\n2020-01-27 19:58:35,117|msrest.http_logger|DEBUG|\\n2020-01-27 19:58:35,118|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-01-27 19:58:42,812|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-01-27 19:58:42,812|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-01-27 19:58:42,812|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 1.\\n2020-01-27 19:58:42,812|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-01-27 19:58:42,812|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-01-27 19:58:42,813|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-01-27 19:58:42,813|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-01-27 19:58:42,813|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.1__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-01-27 19:58:42,814|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-01-27 19:58:42,815|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-01-27 19:58:42,815|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 1__log_batch to queue of approximate size: 1\\n2020-01-27 19:58:42,815|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-01-27 19:58:42,815|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-01-27 19:58:42,816|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-01-27 19:58:42,816|msrest.http_logger|DEBUG|Request URL: 'https://northcentralus.experiments.azureml.net/history/v1.0/subscriptions/102a16c3-37d3-48a8-9237-4c9b1e8e80e0/resourceGroups/automlpmdemo/providers/Microsoft.MachineLearningServices/workspaces/cesardl-automl-northcentralus-ws/experiments/spark-experiment-on-aml-compute/runs/spark-experiment-on-aml-compute_1580155063_b95d3594/batch/metrics'\\n2020-01-27 19:58:42,816|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-01-27 19:58:42,816|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-01-27 19:58:42,817|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-01-27 19:58:42,817|msrest.http_logger|DEBUG|Request headers:\\n2020-01-27 19:58:42,817|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-01-27 19:58:42,817|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-01-27 19:58:42,817|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-01-27 19:58:42,817|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-01-27 19:58:42,818|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-01-27 19:58:42,818|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '47bb97f5-d0a0-4f57-99a4-93cdeff51312'\\n2020-01-27 19:58:42,818|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-01-27 19:58:42,818|msrest.http_logger|DEBUG|    'request-id': '47bb97f5-d0a0-4f57-99a4-93cdeff51312'\\n2020-01-27 19:58:42,819|msrest.http_logger|DEBUG|    'Content-Length': '358'\\n2020-01-27 19:58:42,819|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.2 (Linux-4.15.0-1057-azure-x86_64-with-debian-stretch-sid) msrest/0.6.10 azureml._restclient/core.1.0.81 sdk_run'\\n2020-01-27 19:58:42,819|msrest.http_logger|DEBUG|Request body:\\n2020-01-27 19:58:42,819|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"025edf61-454a-4ab9-9e5b-f4e9781e04f4\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-01-27T19:58:42.804473Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 0.9583333333333334}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-01-27 19:58:42,819|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-01-27 19:58:42,819|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-01-27 19:58:42,819|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-01-27 19:58:42,819|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-01-27 19:58:42,944|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-01-27 19:58:42,945|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-northcentralus-ws/azureml/spark-experiment-on-aml-compute_1580155063_b95d3594/mounts/workspaceblobstore/azureml/spark-experiment-on-aml-compute_1580155063_b95d3594\\n2020-01-27 19:58:42,945|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-northcentralus-ws/azureml/spark-experiment-on-aml-compute_1580155063_b95d3594/mounts/workspaceblobstore/azureml/spark-experiment-on-aml-compute_1580155063_b95d3594 to /mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-northcentralus-ws/azureml/spark-experiment-on-aml-compute_1580155063_b95d3594/mounts/workspaceblobstore/azureml/spark-experiment-on-aml-compute_1580155063_b95d3594\\n2020-01-27 19:58:42,945|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-northcentralus-ws/azureml/spark-experiment-on-aml-compute_1580155063_b95d3594/mounts/workspaceblobstore/azureml/spark-experiment-on-aml-compute_1580155063_b95d3594\\n2020-01-27 19:58:42,945|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2020-01-27 19:58:42,945|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2020-01-27 19:58:42,945|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594|INFO|complete is not setting status for submitted runs.\\n2020-01-27 19:58:42,946|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-01-27 19:58:42,946|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-01-27 19:58:42,946|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-01-27 19:58:42,946|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-01-27 19:58:42,946|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-01-27 19:58:42,947|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-01-27 19:58:42,947|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-01-27 19:58:42,947|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-01-27 19:58:42,947|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-01-27 19:58:42,947|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-01-27 19:58:42,947|azureml.RunStatusContext|DEBUG|[STOP]\\n2020-01-27 19:58:42,947|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-01-27 19:58:42,948|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-01-27 19:58:42,948|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-01-27 19:58:42,948|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [].\\n2020-01-27 19:58:42,948|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-01-27 19:58:42,948|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-01-27 19:58:42,948|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-01-27 19:58:42,948|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-01-27 19:58:42,948|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-01-27 19:58:42,948|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300.0 is different from task queue timeout 120, using flush timeout\\n2020-01-27 19:58:42,949|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300.0 seconds on tasks: [AsyncTask(0__log_batch), AsyncTask(1__log_batch)].\\n2020-01-27 19:58:42,949|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.0__log_batch.WaitingTask|DEBUG|[START]\\n2020-01-27 19:58:42,949|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.0__log_batch.WaitingTask|DEBUG|Awaiter is PostMetricsBatch\\n2020-01-27 19:58:42,949|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.0__log_batch.WaitingTask|DEBUG|[STOP]\\n2020-01-27 19:58:43,043|msrest.http_logger|DEBUG|Response status: 200\\n2020-01-27 19:58:43,043|msrest.http_logger|DEBUG|Response headers:\\n2020-01-27 19:58:43,043|msrest.http_logger|DEBUG|    'Date': 'Mon, 27 Jan 2020 19:58:43 GMT'\\n2020-01-27 19:58:43,043|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-01-27 19:58:43,043|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-01-27 19:58:43,044|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-01-27 19:58:43,044|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '47bb97f5-d0a0-4f57-99a4-93cdeff51312'\\n2020-01-27 19:58:43,044|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-01-27 19:58:43,044|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-01-27 19:58:43,044|msrest.http_logger|DEBUG|    'X-Content-Type-Options': 'nosniff'\\n2020-01-27 19:58:43,044|msrest.http_logger|DEBUG|Response content:\\n2020-01-27 19:58:43,044|msrest.http_logger|DEBUG|\\n2020-01-27 19:58:43,046|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-01-27 19:58:43,200|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.1__log_batch.WaitingTask|DEBUG|[START]\\n2020-01-27 19:58:43,200|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.1__log_batch.WaitingTask|DEBUG|Awaiter is PostMetricsBatch\\n2020-01-27 19:58:43,200|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.1__log_batch.WaitingTask|DEBUG|[STOP]\\n2020-01-27 19:58:43,200|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Waiting on task: 1__log_batch.\\n1 tasks left. Current duration of flush 0.0005588531494140625 seconds.\\n\\n2020-01-27 19:58:43,200|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-01-27 19:58:43,201|azureml._SubmittedRun#spark-experiment-on-aml-compute_1580155063_b95d3594.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-01-27 19:58:43,201|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2020-01-27 19:58:43,201|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2020-01-27 19:58:43,201|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2020-01-27 19:58:43,201|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"NOTSET\", \"sdk_version\": \"1.0.76\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Monitor run\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# See files associated with the 'Best run'\n",
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Regularization Rate': 0.01, 'Accuracy': 0.9787234042553191}\n"
     ]
    }
   ],
   "source": [
    "# get all metris logged in the run\n",
    "metrics = run.get_metrics()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
